{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, EsmForProteinFolding\n",
    "from transformers.models.esm.openfold_utils.protein import to_pdb, Protein as OFProtein\n",
    "from transformers.models.esm.openfold_utils.feats import atom14_to_atom37\n",
    "import torch\n",
    "\n",
    "# Function to convert model outputs to PDB files\n",
    "def convert_outputs_to_pdb(outputs):\n",
    "    final_atom_positions = atom14_to_atom37(outputs[\"positions\"][-1], outputs)\n",
    "    final_atom_positions_np = final_atom_positions.cpu().numpy()\n",
    "    final_atom_mask = outputs[\"atom37_atom_exists\"].cpu().numpy()\n",
    "\n",
    "    pdbs = []\n",
    "    for i in range(outputs[\"aatype\"].shape[0]):\n",
    "        aa = outputs[\"aatype\"][i].cpu().numpy()\n",
    "        pred_pos = final_atom_positions_np[i]\n",
    "        mask = final_atom_mask[i]\n",
    "        resid = outputs[\"residue_index\"][i].cpu().numpy() + 1\n",
    "        pred = OFProtein(\n",
    "            aatype=aa,\n",
    "            atom_positions=pred_pos,\n",
    "            atom_mask=mask,\n",
    "            residue_index=resid,\n",
    "            b_factors=outputs[\"plddt\"][i].cpu().numpy(),\n",
    "            chain_index=outputs[\"chain_index\"][i].cpu().numpy()\n",
    "            if \"chain_index\" in outputs\n",
    "            else None,\n",
    "        )\n",
    "        pdbs.append(to_pdb(pred))\n",
    "    return pdbs\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"facebook/esmfold_v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = EsmForProteinFolding.from_pretrained(model_name, low_cpu_mem_usage=True).cuda()\n",
    "\n",
    "# Uncomment to switch the stem to float16 for memory optimization\n",
    "model.esm = model.esm.half()\n",
    "\n",
    "# Enable TensorFloat32 for faster matrix multiplications\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# Set chunk size optimized for an 11GB GPU\n",
    "model.trunk.set_chunk_size(128)\n",
    "\n",
    "def generate_structures_from_csvs_in_directory(directory_path):\n",
    "    # List all CSV files in the directory\n",
    "    csv_files = [f for f in os.listdir(directory_path) if f.endswith(\".csv\")]\n",
    "\n",
    "    if not csv_files:\n",
    "        print(\"No CSV files found in the directory.\")\n",
    "        return\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = os.path.join(directory_path, csv_file)\n",
    "        print(f\"Processing file: {csv_file}\")\n",
    "\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(csv_path)\n",
    "            if \"sequence\" not in df.columns or \"gene\" not in df.columns:\n",
    "                print(f\"Skipping {csv_file}: Missing 'sequence' or 'gene' column.\")\n",
    "                continue\n",
    "\n",
    "            # Create an output folder in the same directory as the CSV\n",
    "            output_dir = os.path.join(directory_path, os.path.splitext(csv_file)[0] + \"_predicted_structures\")\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # Iterate through sequences and generate structures\n",
    "            for idx, row in df.iterrows():\n",
    "                sequence = row[\"sequence\"]\n",
    "                protein_name = row[\"gene\"]\n",
    "\n",
    "                # Tokenize input\n",
    "                input_ids = tokenizer([sequence], return_tensors=\"pt\", add_special_tokens=False)['input_ids'].cuda()\n",
    "\n",
    "                # Predict structure\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids)\n",
    "\n",
    "                # Convert to PDB\n",
    "                pdbs = convert_outputs_to_pdb(outputs)\n",
    "\n",
    "                # Save each PDB structure\n",
    "                for pdb_idx, pdb in enumerate(pdbs):\n",
    "                    pdb_path = os.path.join(output_dir, f\"{protein_name}_{pdb_idx + 1}.pdb\")\n",
    "                    with open(pdb_path, \"w\") as f:\n",
    "                        f.write(pdb)\n",
    "\n",
    "            print(f\"Successfully processed and saved structures for file: {csv_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {csv_file}: {e}\")\n",
    "        finally:\n",
    "            print(f\"Finished processing file: {csv_file}\")\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"path_to_your_directory\"  # Replace with your directory path\n",
    "generate_structures_from_csvs_in_directory(directory_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
